{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3247cc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from borealis.modeling import BorealisForConditionalGeneration\n",
    "from borealis.dataset import BorealisBaseDataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer, WhisperFeatureExtractor\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff55c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B\")\n",
    "\n",
    "start_audio_token = \"<|start_of_audio|>\"\n",
    "end_audio_token = \"<|end_of_audio|>\"\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "    {\"additional_special_tokens\": [start_audio_token, end_audio_token]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31dd6830",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Vikhrmodels/ToneSpeak\", cache_dir=\"../cache_home/\")\n",
    "ds = ds.cast_column(\"audio\", Audio(decode=True, sampling_rate=16_000))\n",
    "\n",
    "whisper_encoder = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1777f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BorealisForConditionalGeneration(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabb1f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\"/workspace/Borealis/asr_qwen_ckpts/checkpoint-17247/pytorch_model.bin\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ad4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3e352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = BorealisBaseDataset(\n",
    "    audio_processor=whisper_encoder,\n",
    "    text_tokenizer=tokenizer,\n",
    "    audios=ds[\"validation\"][\"audio\"][:4],\n",
    "    texts=ds[\"validation\"][\"text\"][:4],\n",
    "    max_text_len=320,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "474874b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d69ba4b96c459fa127423c955a726c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference on eval set:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сегодня утром, когда ветер ласково трепал листьями на деревьях, я решила прогуляться по парку и насладиться свежим воздухом, который наполнял душу, спокойствием и радостью.\n",
      "Сегодня утром, когда ветер ласково трепал листья на деревьях, я решила прогуляться по парку и насладиться свежим воздухом, который наполнял душу спокойствием и радостью.\n",
      "Вечерние огни города плавно загораются, отражаясь в спокойной воде реки, создавая чарующую атмосферу уйтра и тихого умиротворения для всех, кто прогуливается по набережной.\n",
      "Вечерние огни города плавно загораются, отражаясь в спокойной воде реки, создавая чарующую атмосферу уюта и тихого умиротворения для всех, кто прогуливается по набережной.\n",
      "Сегодня утром солнце ярко сияло над горизонтом, освещая зеленые поля и пробуждая в туше легкое чувство радости и умиротворения.\n",
      "Сегодня утром солнце ярко сияло над горизонтом, освещая зелёные поля и пробуждая в душе лёгкое чувство радости и умиротворения.\n",
      "Вечерняя прогулка по парку всегда приносит особое чувство, умиротворение и вдохновение, когда легкий ветер играет с листьями, а солнце постепенно ласкает горизонт своими золотистыми дучами.\n",
      "Вечерняя прогулка по парку всегда приносит особое чувство умиротворения и вдохновения, когда лёгкий ветер играет с листьями, а солнце постепенно ласкает горизонт своими золотистыми лучами.\n",
      "Сгенерировано: С\n",
      "Правильный текст: С\n",
      "--------------------------------------------------------------------------------\n",
      "Сгенерировано: е\n",
      "Правильный текст: е\n",
      "--------------------------------------------------------------------------------\n",
      "Сгенерировано: г\n",
      "Правильный текст: г\n",
      "--------------------------------------------------------------------------------\n",
      "Сгенерировано: о\n",
      "Правильный текст: о\n",
      "--------------------------------------------------------------------------------\n",
      "Сгенерировано: д\n",
      "Правильный текст: д\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "generated_transcripts = []\n",
    "ground_truth_texts = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch in tqdm(eval_dataset, desc=\"Inference on eval set\"):\n",
    "        mel = batch[\"mel\"].to(model.encoder.device)  # (B, 128, 3000)\n",
    "        att_mask = batch[\"audio_att_mask\"].to(model.encoder.device)  # (B, 3000)\n",
    "\n",
    "        transcripts = model.generate(\n",
    "            mel=mel,\n",
    "            att_mask=att_mask,\n",
    "            max_new_tokens=320,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "        )\n",
    "        print(transcripts)\n",
    "\n",
    "        gt_texts = tokenizer.decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "\n",
    "        print(gt_texts)\n",
    "\n",
    "        generated_transcripts.extend(transcripts)\n",
    "        ground_truth_texts.extend(gt_texts)\n",
    "\n",
    "\n",
    "for i in range(min(5, len(generated_transcripts))):\n",
    "    print(f\"Сгенерировано: {generated_transcripts[i]}\")\n",
    "    print(f\"Правильный текст: {ground_truth_texts[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9437044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def test_single_wav(\n",
    "    wav_path: str,\n",
    "    model: BorealisForConditionalGeneration,\n",
    "    audio_processor: WhisperFeatureExtractor,\n",
    "    max_seconds_len: float = 30.0,\n",
    "    sampling_rate: int = 16000,\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    generation_params: dict = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Загружает один WAV файл, обрабатывает его и генерирует транскрипт с помощью модели.\n",
    "\n",
    "    :param wav_path: Путь к WAV файлу.\n",
    "    :param model: Инстанс WhisperQWenASRModel.\n",
    "    :param audio_processor: WhisperFeatureExtractor для обработки аудио.\n",
    "    :param max_seconds_len: Максимальная длина аудио в секундах (для паддинга).\n",
    "    :param sampling_rate: Частота дискретизации (по умолчанию 16000).\n",
    "    :param device: Устройство ('cuda' или 'cpu').\n",
    "    :param generation_params: Словарь с параметрами для model.generate (например, {'temperature': 0.0, 'max_new_tokens': 320}).\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    waveform, sr = torchaudio.load(wav_path)\n",
    "    if sr != sampling_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sr, sampling_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    waveform = waveform.mean(dim=0).numpy()  # (T,)\n",
    "\n",
    "    proc = audio_processor(\n",
    "        waveform,\n",
    "        sampling_rate=sampling_rate,\n",
    "        padding=\"max_length\",\n",
    "        max_length=int(max_seconds_len * sampling_rate),\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    mel = proc.input_features.squeeze(0).to(device)  # (80, 3000)\n",
    "    att_mask = proc.attention_mask.squeeze(0).to(device)  # (3000)\n",
    "\n",
    "    if generation_params is None:\n",
    "        generation_params = {\n",
    "            \"max_new_tokens\": 320,\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 50,\n",
    "        }\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        transcript = model.generate(mel=mel, att_mask=att_mask, **generation_params)\n",
    "\n",
    "    print(f\"Generated transcript for {wav_path}:\")\n",
    "    print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caddf99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated transcript for /workspace/res.wav:\n",
      "Смехал грека через реку, видит грека в реку, рак за руку греку, цап!\n"
     ]
    }
   ],
   "source": [
    "test_single_wav(\n",
    "    wav_path=\"/workspace/res.wav\",\n",
    "    model=model,\n",
    "    audio_processor=whisper_encoder,\n",
    "    generation_params={\n",
    "        \"top_p\": 0.9,\n",
    "        \"do_sample\": True,\n",
    "        \"max_new_tokens\": 320,\n",
    "        \"temperature\": 0.95,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41607894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since Vikhrmodels/ToneRuLS couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/.cache/huggingface/datasets/Vikhrmodels___tone_ru_ls/default/0.0.0/4f7ee71a5b072597dc935538a82c958c80f9699c (last modified on Wed Jul 23 15:46:50 2025).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58469d81e6e041c3a04e8e4f2baf5c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = load_dataset(\"Vikhrmodels/ToneRuLS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5997be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', 'text', 'text_with_preprocessing'],\n",
       "        num_rows: 53218\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['audio', 'text', 'text_with_preprocessing'],\n",
       "        num_rows: 4006\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c217947",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = BorealisBaseDataset(\n",
    "    audio_processor=whisper_encoder,\n",
    "    text_tokenizer=tokenizer,\n",
    "    audios=test_ds[\"validation\"][\"audio\"][:79],\n",
    "    texts=test_ds[\"validation\"][\"text\"][:79],\n",
    "    max_text_len=320,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2863b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8eadfc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mel': tensor([[ 0.0308, -0.4614, -0.4598,  ..., -0.8413, -0.8413, -0.8413],\n",
       "         [ 0.1283, -0.3639, -0.3623,  ..., -0.8413, -0.8413, -0.8413],\n",
       "         [ 0.2090, -0.0085, -0.0587,  ..., -0.8413, -0.8413, -0.8413],\n",
       "         ...,\n",
       "         [-0.8413, -0.8413, -0.8413,  ..., -0.8413, -0.8413, -0.8413],\n",
       "         [-0.8413, -0.8413, -0.8413,  ..., -0.8413, -0.8413, -0.8413],\n",
       "         [-0.8413, -0.8413, -0.8413,  ..., -0.8413, -0.8413, -0.8413]]),\n",
       " 'audio_att_mask': tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32),\n",
       " 'labels': tensor([ 20195,   8178,     11, 126081, 127287,  18943, 139732,     11,   8215,\n",
       "         137477, 134378,  45310,  10813, 128399,  46195,   5805,  12121,  18492,\n",
       "             11,  18658,  85191,   4824, 125469, 126491,  11310, 126118,     11,\n",
       "         126491,  57217,  31885,  30343,     11, 126491,  54517,  19077,  16748,\n",
       "             11, 126491,  11310,   7336,  22496,   1802,     13, 151645, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,\n",
       "         151643, 151643, 151643, 151643, 151643]),\n",
       " 'text_att_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1988bb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122eb2ff743e4e3cbeba0e1b68b2a85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Inference on eval set:   0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_transcripts = []\n",
    "ground_truth_texts = []\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for batch in tqdm(eval_dataset, desc=\"Inference on eval set\"):\n",
    "        mel = batch[\"mel\"].to(model.encoder.device)  # (B, 128, 3000)\n",
    "        att_mask = batch[\"audio_att_mask\"].to(model.encoder.device)  # (B, 3000)\n",
    "\n",
    "        transcripts = model.generate(\n",
    "            mel=mel,\n",
    "            att_mask=att_mask,\n",
    "            max_new_tokens=320,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "        )\n",
    "\n",
    "        gt_texts = tokenizer.decode(batch[\"labels\"], skip_special_tokens=True)\n",
    "\n",
    "        generated_transcripts.append(transcripts)\n",
    "        ground_truth_texts.append(gt_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "941bfa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_text_list(text_list):\n",
    "    # Создаем множество символов пунктуации\n",
    "    punct = set(string.punctuation)\n",
    "    \n",
    "    # Обрабатываем каждый текст в списке\n",
    "    cleaned_list = [\n",
    "        ''.join(char for char in text.lower() if char not in punct)\n",
    "        for text in text_list\n",
    "    ]\n",
    "    \n",
    "    return cleaned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37fa01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_score = wer(clean_text_list(ground_truth_texts), clean_text_list(generated_transcripts))\n",
    "cer_score = cer(clean_text_list(ground_truth_texts), clean_text_list(generated_transcripts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f64633c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21387832699619772"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8208b050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10763052208835341"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cer_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c514fe9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version n7.0.2-189-gf98f142da5 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "built with gcc 11 (Ubuntu 11.4.0-1ubuntu1~22.04)\n",
      "configuration: --enable-gpl --enable-libx264 --enable-libx265 --enable-libvpx --enable-libfdk-aac --enable-libmp3lame --enable-libopus --enable-libdav1d --enable-libass --enable-libfreetype --enable-sdl2 --enable-nonfree\n",
      "libavutil      59.  8.100 / 59.  8.100\n",
      "libavcodec     61.  3.100 / 61.  3.100\n",
      "libavformat    61.  1.100 / 61.  1.100\n",
      "libavdevice    61.  1.100 / 61.  1.100\n",
      "libavfilter    10.  1.100 / 10.  1.100\n",
      "libswscale      8.  1.100 /  8.  1.100\n",
      "libswresample   5.  1.100 /  5.  1.100\n",
      "libpostproc    58.  1.100 / 58.  1.100\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e90a404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестируем сэмпл с индексом: 3\n",
      "Ошибка при загрузке сэмпла 3: The frame has 0 channels, expected 1. If you are hitting this, it may be because you are using a buggy FFmpeg version. FFmpeg4 is known to fail here in some valid scenarios. Try to upgrade FFmpeg?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'torchcodec.decoders.AudioDecoder' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtest_random_sample\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     sample = \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mСэмпл успешно загружен!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Borealis/borealis/dataset.py:35\u001b[39m, in \u001b[36mBorealisBaseDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     audio_sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maudios\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     36\u001b[39m     text_sample = \u001b[38;5;28mself\u001b[39m.texts[index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Borealis/audio_llm_venv/lib/python3.13/site-packages/datasets/features/_torchcodec.py:8\u001b[39m, in \u001b[36mAudioDecoder.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     y = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_all_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.data.cpu().numpy()\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(y, axis=\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(y.ndim - \u001b[32m1\u001b[39m))) \u001b[38;5;28;01mif\u001b[39;00m y.ndim > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Borealis/audio_llm_venv/lib/python3.13/site-packages/torchcodec/decoders/_audio_decoder.py:97\u001b[39m, in \u001b[36mAudioDecoder.get_all_samples\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns all the audio samples from the source.\u001b[39;00m\n\u001b[32m     90\u001b[39m \n\u001b[32m     91\u001b[39m \u001b[33;03mTo decode samples in a specific range, use\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m    AudioSamples: The samples within the file.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_samples_played_in_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Borealis/audio_llm_venv/lib/python3.13/site-packages/torchcodec/decoders/_audio_decoder.py:126\u001b[39m, in \u001b[36mAudioDecoder.get_samples_played_in_range\u001b[39m\u001b[34m(self, start_seconds, stop_seconds)\u001b[39m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    124\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid start seconds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_seconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. It must be less than or equal to stop seconds (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop_seconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    125\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m frames, first_pts = \u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_frames_by_pts_in_range_audio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m first_pts = first_pts.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Borealis/audio_llm_venv/lib/python3.13/site-packages/torch/_ops.py:756\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The frame has 0 channels, expected 1. If you are hitting this, it may be because you are using a buggy FFmpeg version. FFmpeg4 is known to fail here in some valid scenarios. Try to upgrade FFmpeg?",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mПуть к аудио:\u001b[39m\u001b[33m\"\u001b[39m, dataset.audios[index][\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Запуск теста\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mtest_random_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mtest_random_sample\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОшибка при загрузке сэмпла \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Если ошибка в конкретном файле, можно добавить больше отладки\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudios\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mПуть к аудио:\u001b[39m\u001b[33m\"\u001b[39m, dataset.audios[index][\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Borealis/audio_llm_venv/lib/python3.13/site-packages/datasets/features/_torchcodec.py:15\u001b[39m, in \u001b[36mAudioDecoder.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getitem__\u001b[39m(key)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtorchcodec.decoders.AudioDecoder\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object is not subscriptable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'torchcodec.decoders.AudioDecoder' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def test_random_sample(dataset):\n",
    "    if len(dataset) == 0:\n",
    "        print(\"Датасет пустой!\")\n",
    "        return\n",
    "    \n",
    "    index = random.randint(0, len(dataset) - 1)\n",
    "    print(f\"Тестируем сэмпл с индексом: {index}\")\n",
    "    \n",
    "    try:\n",
    "        sample = dataset[index]\n",
    "        print(\"Сэмпл успешно загружен!\")\n",
    "        print(\"Ключи в сэмпле:\", list(sample.keys()))\n",
    "        \n",
    "        # Печать форм (для отладки)\n",
    "        print(\"Форма mel:\", sample[\"mel\"].shape)\n",
    "        print(\"Форма audio_att_mask:\", sample[\"audio_att_mask\"].shape)\n",
    "        print(\"Форма labels:\", sample[\"labels\"].shape)\n",
    "        print(\"Форма text_att_mask:\", sample[\"text_att_mask\"].shape)\n",
    "        \n",
    "        # Опционально: декодировать текст для проверки\n",
    "        decoded_text = dataset.tokenizer.decode(sample[\"labels\"], skip_special_tokens=True)\n",
    "        print(\"Декодированный текст:\", decoded_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке сэмпла {index}: {e}\")\n",
    "        # Если ошибка в конкретном файле, можно добавить больше отладки\n",
    "        if \"path\" in dataset.audios[index]:\n",
    "            print(\"Путь к аудио:\", dataset.audios[index][\"path\"])\n",
    "\n",
    "# Запуск теста\n",
    "test_random_sample(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca11fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio_llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
